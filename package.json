{
  "name": "retell-groq-custom-llm",
  "version": "1.0.0",
  "description": "Retell AI Custom LLM server using Groq Llama",
  "main": "src/index.ts",
  "scripts": {
    "build": "tsc",
    "start": "node dist/index.js",
    "dev": "npx nodemon src/index.ts"
  },
  "dependencies": {
    "express": "^4.18.2",
    "express-ws": "^5.0.2",
    "groq-sdk": "^0.5.0",
    "retell-sdk": "^4.6.0",
    "dotenv": "^16.4.1"
  },
  "devDependencies": {
    "@types/express": "^4.17.21",
    "@types/express-ws": "^3.0.5",
    "@types/node": "^20.11.5",
    "ts-node": "^10.9.2",
    "typescript": "^5.3.3",
    "nodemon": "^3.0.3"
  }
}
